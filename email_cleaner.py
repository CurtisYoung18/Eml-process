#!/usr/bin/env python3
"""
é‚®ä»¶æ¸…æ´—è„šæœ¬ - ç¬¬ä¸€è½®æ¸…æ´—
åŠŸèƒ½ï¼šè§£æEMLæ–‡ä»¶ï¼Œå»é‡ï¼Œç”ŸæˆMarkdownæ ¼å¼æ–‡ä»¶
"""

import os
import re
import email
import json
from pathlib import Path
from email.header import decode_header
from email.utils import parsedate_to_datetime
from typing import Dict, List, Tuple, Optional
from datetime import datetime
import hashlib

class EmailCleaner:
    def __init__(self, input_dir: str = "Eml", output_dir: str = "eml_process/processed"):
        """
        åˆå§‹åŒ–é‚®ä»¶æ¸…æ´—å™¨
        
        Args:
            input_dir: è¾“å…¥EMLæ–‡ä»¶ç›®å½•
            output_dir: è¾“å‡ºMarkdownæ–‡ä»¶ç›®å½•
        """
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # å­˜å‚¨å¤„ç†è¿‡çš„é‚®ä»¶ä¿¡æ¯
        self.processed_emails = []
        self.duplicate_info = []
        
    def decode_email_header(self, header_value: str) -> str:
        """è§£ç é‚®ä»¶å¤´éƒ¨ä¿¡æ¯"""
        if not header_value:
            return ""
        
        try:
            decoded_parts = decode_header(header_value)
            result = ""
            for part, encoding in decoded_parts:
                if isinstance(part, bytes):
                    if encoding:
                        result += part.decode(encoding)
                    else:
                        result += part.decode('utf-8', errors='ignore')
                else:
                    result += str(part)
            return result.strip()
        except Exception as e:
            print(f"âš ï¸ å¤´éƒ¨è§£ç å¤±è´¥: {e}")
            return str(header_value)
    
    def extract_email_content(self, msg) -> str:
        """æå–é‚®ä»¶æ­£æ–‡å†…å®¹"""
        content = ""
        
        if msg.is_multipart():
            for part in msg.walk():
                content_type = part.get_content_type()
                content_disposition = str(part.get("Content-Disposition"))
                
                # åªå¤„ç†æ–‡æœ¬å†…å®¹ï¼Œå¿½ç•¥é™„ä»¶
                if content_type == "text/plain" and "attachment" not in content_disposition:
                    try:
                        payload = part.get_payload(decode=True)
                        if payload:
                            charset = part.get_content_charset() or 'utf-8'
                            content += payload.decode(charset, errors='ignore') + "\n"
                    except Exception as e:
                        print(f"âš ï¸ å†…å®¹è§£ç å¤±è´¥: {e}")
                        
                elif content_type == "text/html" and "attachment" not in content_disposition and not content:
                    # å¦‚æœæ²¡æœ‰çº¯æ–‡æœ¬ï¼Œå°è¯•HTMLï¼ˆç®€å•å¤„ç†ï¼‰
                    try:
                        payload = part.get_payload(decode=True)
                        if payload:
                            charset = part.get_content_charset() or 'utf-8'
                            html_content = payload.decode(charset, errors='ignore')
                            # ç®€å•å»é™¤HTMLæ ‡ç­¾
                            clean_content = re.sub(r'<[^>]+>', '', html_content)
                            content += clean_content + "\n"
                    except Exception as e:
                        print(f"âš ï¸ HTMLå†…å®¹è§£ç å¤±è´¥: {e}")
        else:
            # éå¤šéƒ¨åˆ†é‚®ä»¶
            try:
                payload = msg.get_payload(decode=True)
                if payload:
                    charset = msg.get_content_charset() or 'utf-8'
                    content = payload.decode(charset, errors='ignore')
            except Exception as e:
                print(f"âš ï¸ é‚®ä»¶å†…å®¹è§£ç å¤±è´¥: {e}")
        
        return content.strip()
    
    def clean_content(self, content: str) -> str:
        """æ¸…ç†é‚®ä»¶å†…å®¹"""
        if not content:
            return ""
        
        # ç§»é™¤å¤šä½™çš„ç©ºç™½è¡Œ
        content = re.sub(r'\n\s*\n\s*\n', '\n\n', content)
        
        # ç§»é™¤é‚®ä»¶å¤´éƒ¨çš„æŠ€æœ¯ä¿¡æ¯ï¼ˆReceived, Message-IDç­‰ï¼‰
        lines = content.split('\n')
        cleaned_lines = []
        skip_technical = False
        
        for line in lines:
            line = line.strip()
            
            # è·³è¿‡æŠ€æœ¯å¤´éƒ¨ä¿¡æ¯
            if line.startswith(('Received:', 'Message-ID:', 'Return-Path:', 'X-')):
                skip_technical = True
                continue
            elif skip_technical and line and not line.startswith(' '):
                skip_technical = False
            
            if not skip_technical:
                cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines).strip()
    
    def parse_eml_file(self, file_path: Path) -> Optional[Dict]:
        """è§£æå•ä¸ªEMLæ–‡ä»¶"""
        try:
            with open(file_path, 'rb') as f:
                msg = email.message_from_bytes(f.read())
            
            # æå–åŸºæœ¬ä¿¡æ¯
            email_info = {
                'filename': file_path.name,
                'from': self.decode_email_header(msg.get('From', '')),
                'to': self.decode_email_header(msg.get('To', '')),
                'cc': self.decode_email_header(msg.get('Cc', '')),
                'subject': self.decode_email_header(msg.get('Subject', '')),
                'date': msg.get('Date', ''),
                'content': self.extract_email_content(msg)
            }
            
            # è§£ææ—¥æœŸ
            try:
                if email_info['date']:
                    parsed_date = parsedate_to_datetime(email_info['date'])
                    email_info['parsed_date'] = parsed_date
                    email_info['date_str'] = parsed_date.strftime('%Y-%m-%d %H:%M:%S')
                else:
                    email_info['parsed_date'] = None
                    email_info['date_str'] = "æœªçŸ¥æ—¶é—´"
            except:
                email_info['parsed_date'] = None
                email_info['date_str'] = "æœªçŸ¥æ—¶é—´"
            
            # æ¸…ç†å†…å®¹
            email_info['cleaned_content'] = self.clean_content(email_info['content'])
            
            # ç”Ÿæˆå†…å®¹å“ˆå¸Œç”¨äºå»é‡
            content_for_hash = email_info['cleaned_content'].lower().replace(' ', '').replace('\n', '')
            email_info['content_hash'] = hashlib.md5(content_for_hash.encode()).hexdigest()
            
            return email_info
            
        except Exception as e:
            print(f"âŒ è§£ææ–‡ä»¶å¤±è´¥ {file_path.name}: {e}")
            return None
    
    def find_duplicates(self, emails: List[Dict]) -> Tuple[List[Dict], List[Dict]]:
        """æŸ¥æ‰¾å¹¶å¤„ç†é‡å¤é‚®ä»¶ - 100%å†…å®¹åŒ…å«æ£€æµ‹"""
        # æŒ‰å†…å®¹é•¿åº¦æ’åºï¼ˆé•¿çš„åœ¨å‰ï¼‰
        emails_sorted = sorted(emails, key=lambda x: len(x['cleaned_content']), reverse=True)
        
        unique_emails = []
        duplicates = []
        
        for email_info in emails_sorted:
            # æ ‡å‡†åŒ–å†…å®¹ç”¨äºæ¯”è¾ƒ - ç§»é™¤æ‰€æœ‰ç©ºç™½å­—ç¬¦å’Œæ¢è¡Œ
            current_content = re.sub(r'\s+', '', email_info['cleaned_content'].lower())
            
            is_duplicate = False
            container_email = None
            
            # æ£€æŸ¥å½“å‰é‚®ä»¶æ˜¯å¦è¢«å·²å¤„ç†çš„é‚®ä»¶100%åŒ…å«
            for unique_email in unique_emails:
                unique_content = re.sub(r'\s+', '', unique_email['cleaned_content'].lower())
                
                # 100%åŒ…å«æ£€æµ‹ï¼šè¾ƒçŸ­å†…å®¹å¿…é¡»å®Œå…¨åœ¨è¾ƒé•¿å†…å®¹ä¸­
                if (len(current_content) > 0 and 
                    len(current_content) <= len(unique_content) and 
                    current_content in unique_content):
                    is_duplicate = True
                    container_email = unique_email
                    break
            
            if is_duplicate and container_email:
                # è®°å½•é‡å¤ä¿¡æ¯
                duplicates.append({
                    'duplicate_file': email_info['filename'],
                    'duplicate_subject': email_info['subject'],
                    'contained_by_file': container_email['filename'],
                    'contained_by_subject': container_email['subject'],
                    'content_length_ratio': f"{len(current_content)}/{len(re.sub(r'\s+', '', container_email['cleaned_content'].lower()))}"
                })
                
                # åœ¨å®¹å™¨é‚®ä»¶ä¸­è®°å½•åŒ…å«çš„æºæ–‡ä»¶
                if 'contained_files' not in container_email:
                    container_email['contained_files'] = []
                container_email['contained_files'].append(email_info['filename'])
                
                print(f"ğŸ” å‘ç°100%åŒ…å«: {email_info['filename']} è¢« {container_email['filename']} åŒ…å«")
                
            else:
                # ä¸æ˜¯é‡å¤é‚®ä»¶ï¼Œæ·»åŠ åˆ°å”¯ä¸€åˆ—è¡¨
                unique_emails.append(email_info)
                print(f"âœ… ç‹¬ç‰¹é‚®ä»¶: {email_info['filename']} (é•¿åº¦: {len(current_content)})")
        
        return unique_emails, duplicates
    
    def generate_markdown(self, email_info: Dict) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„é‚®ä»¶å†…å®¹"""
        md_content = []
        
        # æ ‡é¢˜
        md_content.append(f"# é‚®ä»¶å†…å®¹ - {email_info['filename']}")
        md_content.append("")
        
        # åŸºæœ¬ä¿¡æ¯
        md_content.append("## ğŸ“§ é‚®ä»¶ä¿¡æ¯")
        md_content.append("")
        md_content.append(f"- **æºæ–‡ä»¶å**: `{email_info['filename']}`")
        md_content.append(f"- **å‘ä»¶äºº**: {email_info['from']}")
        md_content.append(f"- **æ”¶ä»¶äºº**: {email_info['to']}")
        
        if email_info['cc']:
            md_content.append(f"- **æŠ„é€**: {email_info['cc']}")
        
        md_content.append(f"- **ä¸»é¢˜**: {email_info['subject']}")
        md_content.append(f"- **æ—¶é—´**: {email_info['date_str']}")
        
        # å¦‚æœåŒ…å«å…¶ä»–æ–‡ä»¶ï¼Œåˆ—å‡ºæ¥
        if 'contained_files' in email_info:
            md_content.append(f"- **åŒ…å«çš„å…¶ä»–é‚®ä»¶**: {len(email_info['contained_files'])} å°")
            md_content.append("")
            md_content.append("### ğŸ“‹ åŒ…å«çš„æºæ–‡ä»¶åˆ—è¡¨")
            md_content.append("")
            for contained_file in email_info['contained_files']:
                md_content.append(f"- `{contained_file}`")
        
        md_content.append("")
        
        # é‚®ä»¶å†…å®¹
        md_content.append("## ğŸ“„ é‚®ä»¶å†…å®¹")
        md_content.append("")
        
        if email_info['cleaned_content']:
            # å°†é‚®ä»¶å†…å®¹æŒ‰æ®µè½åˆ†å‰²ï¼Œä¿æŒæ ¼å¼
            content_lines = email_info['cleaned_content'].split('\n')
            for line in content_lines:
                if line.strip():
                    md_content.append(line)
                else:
                    md_content.append("")
        else:
            md_content.append("*ï¼ˆé‚®ä»¶å†…å®¹ä¸ºç©ºæˆ–æ— æ³•è§£æï¼‰*")
        
        md_content.append("")
        md_content.append("---")
        md_content.append(f"*å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")
        
        return '\n'.join(md_content)
    
    def save_markdown_file(self, email_info: Dict) -> str:
        """ä¿å­˜Markdownæ–‡ä»¶"""
        # ç”Ÿæˆæ–‡ä»¶åï¼ˆå»é™¤.emlæ‰©å±•åï¼Œæ·»åŠ .mdï¼‰
        base_name = email_info['filename'].replace('.eml', '')
        md_filename = f"{base_name}.md"
        md_path = self.output_dir / md_filename
        
        # ç”ŸæˆMarkdownå†…å®¹
        md_content = self.generate_markdown(email_info)
        
        # ä¿å­˜æ–‡ä»¶
        try:
            with open(md_path, 'w', encoding='utf-8') as f:
                f.write(md_content)
            return str(md_path)
        except Exception as e:
            print(f"âŒ ä¿å­˜Markdownæ–‡ä»¶å¤±è´¥ {md_filename}: {e}")
            return ""
    
    def process_all_emails(self) -> Dict:
        """å¤„ç†æ‰€æœ‰é‚®ä»¶æ–‡ä»¶"""
        print(f"ğŸ” æ‰«æç›®å½•: {self.input_dir}")
        
        # è·å–æ‰€æœ‰EMLæ–‡ä»¶
        eml_files = list(self.input_dir.glob("*.eml"))
        
        if not eml_files:
            print(f"âŒ æœªåœ¨ {self.input_dir} ä¸­æ‰¾åˆ°EMLæ–‡ä»¶")
            return {"success": False, "message": "æœªæ‰¾åˆ°EMLæ–‡ä»¶"}
        
        print(f"ğŸ“§ å‘ç° {len(eml_files)} ä¸ªEMLæ–‡ä»¶")
        
        # è§£ææ‰€æœ‰é‚®ä»¶
        emails = []
        failed_files = []
        
        for eml_file in eml_files:
            print(f"ğŸ“– è§£æ: {eml_file.name}")
            email_info = self.parse_eml_file(eml_file)
            
            if email_info:
                emails.append(email_info)
            else:
                failed_files.append(eml_file.name)
        
        if not emails:
            return {"success": False, "message": "æ‰€æœ‰é‚®ä»¶è§£æå¤±è´¥"}
        
        print(f"âœ… æˆåŠŸè§£æ {len(emails)} ä¸ªé‚®ä»¶")
        
        # å»é‡å¤„ç†
        print("ğŸ”„ å¼€å§‹å»é‡å¤„ç†...")
        unique_emails, duplicates = self.find_duplicates(emails)
        
        print(f"ğŸ“Š å»é‡ç»“æœ: {len(emails)} -> {len(unique_emails)} å°é‚®ä»¶")
        print(f"ğŸ—‘ï¸ é‡å¤é‚®ä»¶: {len(duplicates)} å°")
        
        # ç”ŸæˆMarkdownæ–‡ä»¶
        print("ğŸ“ ç”ŸæˆMarkdownæ–‡ä»¶...")
        generated_files = []
        
        for email_info in unique_emails:
            md_path = self.save_markdown_file(email_info)
            if md_path:
                generated_files.append(md_path)
                print(f"âœ… ç”Ÿæˆ: {Path(md_path).name}")
        
        # ä¿å­˜å¤„ç†æŠ¥å‘Š
        report = {
            "processing_time": datetime.now().isoformat(),
            "input_directory": str(self.input_dir),
            "output_directory": str(self.output_dir),
            "total_input_files": len(eml_files),
            "successfully_parsed": len(emails),
            "failed_to_parse": len(failed_files),
            "failed_files": failed_files,
            "unique_emails": len(unique_emails),
            "duplicate_emails": len(duplicates),
            "duplicate_details": duplicates,
            "generated_markdown_files": [Path(f).name for f in generated_files],
            "compression_ratio": f"{len(duplicates) / len(emails) * 100:.1f}%" if emails else "0%"
        }
        
        report_path = self.output_dir / "processing_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“‹ å¤„ç†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        print(f"ğŸ“Š å‹ç¼©ç‡: {report['compression_ratio']}")
        
        return {
            "success": True,
            "report": report,
            "generated_files": generated_files
        }

def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œä½¿ç”¨"""
    print("ğŸš€ é‚®ä»¶æ¸…æ´—è„šæœ¬å¯åŠ¨")
    print("=" * 50)
    
    # åˆ›å»ºæ¸…æ´—å™¨å®ä¾‹
    cleaner = EmailCleaner()
    
    # å¤„ç†é‚®ä»¶
    result = cleaner.process_all_emails()
    
    if result["success"]:
        print("\nğŸ‰ é‚®ä»¶æ¸…æ´—å®Œæˆ!")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {cleaner.output_dir}")
        print(f"ğŸ“„ ç”Ÿæˆæ–‡ä»¶æ•°: {len(result['generated_files'])}")
    else:
        print(f"\nâŒ å¤„ç†å¤±è´¥: {result['message']}")

if __name__ == "__main__":
    main()
