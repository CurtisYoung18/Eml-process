"""
çŸ¥è¯†åº“ç®¡ç†æ¨¡å—
å¤„ç†çŸ¥è¯†åº“ä¸Šä¼ å’Œç®¡ç†åŠŸèƒ½
"""

import streamlit as st
import pandas as pd
import json
from pathlib import Path
from datetime import datetime
from .utils import count_files, log_activity


def show_knowledge_base_page():
    """æ˜¾ç¤ºçŸ¥è¯†åº“ç®¡ç†é¡µé¢"""
    from app import CONFIG
    
    st.header("çŸ¥è¯†åº“ç®¡ç†")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰LLMå¤„ç†åçš„æ–‡ä»¶
    final_files = count_files(CONFIG["final_dir"], "*.md")
    
    if final_files == 0:
        st.warning("âš ï¸ æœªå‘ç°LLMå¤„ç†åçš„æ–‡ä»¶ï¼Œè¯·å…ˆå®Œæˆå‰é¢çš„å¤„ç†æ­¥éª¤ã€‚")
        st.info("ğŸ’¡ éœ€è¦å…ˆå®Œæˆï¼šé‚®ä»¶ä¸Šä¼  â†’ æ•°æ®æ¸…æ´— â†’ LLMå¤„ç†ï¼Œç„¶åæ‰èƒ½ä¸Šä¼ åˆ°çŸ¥è¯†åº“")
        return
    
    st.success(f"âœ… å‘ç° {final_files} ä¸ªLLMå¤„ç†åçš„æ–‡ä»¶å¯ä¸Šä¼ åˆ°çŸ¥è¯†åº“")
    
    # APIé…ç½®åŒºåŸŸ
    st.subheader("ğŸ”‘ APIé…ç½®")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # èŠ‚ç‚¹é€‰æ‹©
        endpoint = st.selectbox(
            "é€‰æ‹©APIèŠ‚ç‚¹",
            options=["sg", "cn", "th"],
            index=0,  # é»˜è®¤sg
            format_func=lambda x: {
                "sg": "ğŸŒ æ–°åŠ å¡ (sg) - æ¨è",
                "cn": "ğŸ‡¨ğŸ‡³ ä¸­å›½ (cn)",
                "th": "ğŸ‡¹ğŸ‡­ æ³°å›½ (th)"
            }[x],
            help="é€‰æ‹©GPTBots APIæ•°æ®ä¸­å¿ƒèŠ‚ç‚¹",
            key="kb_endpoint"
        )
    
    with col2:
        # API Keyé€‰æ‹©å™¨
        from .api_selector import create_api_selector_with_guide
        api_key, key_number = create_api_selector_with_guide(
            purpose="knowledge_base",
            key_prefix="kb_management",
            show_guide=True
        )
        
        if not api_key:
            st.warning("âš ï¸ è¯·é…ç½®çŸ¥è¯†åº“API Key")
            st.info("ğŸ’¡ è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®GPTBOTS_KB_API_KEY_1ç­‰ç¯å¢ƒå˜é‡")
            return
        
        # æ˜¾ç¤ºAPI Keyç”¨é€”è¯´æ˜
        with st.expander("ğŸ’¡ API Keyç”¨é€”è¯´æ˜"):
            st.markdown("""
            **çŸ¥è¯†åº“API Keyç”¨é€”:**
            - ğŸ“‹ è·å–çŸ¥è¯†åº“åˆ—è¡¨
            - ğŸ“¤ æ‰¹é‡ä¸Šä¼ æ–‡æ¡£åˆ°çŸ¥è¯†åº“
            - ğŸ” æŸ¥è¯¢æ–‡æ¡£çŠ¶æ€
            - ğŸ“Š ç®¡ç†çŸ¥è¯†åº“å†…å®¹
            
            **æ³¨æ„**: æ­¤API Keyä¹Ÿå¯ä»¥ç”¨äºåç»­çš„é—®ç­”åŠŸèƒ½
            """)
    
    # è·å–çŸ¥è¯†åº“åˆ—è¡¨
    st.subheader("ğŸ“‹ çŸ¥è¯†åº“åˆ—è¡¨")
    if st.button("ğŸ”„ åˆ·æ–°çŸ¥è¯†åº“åˆ—è¡¨", key="get_kb_list_btn"):
        st.session_state.knowledge_bases = get_knowledge_base_list(api_key)
    
    st.markdown("---")
    
    # ä¸Šä¼ é…ç½®åŒºåŸŸ
    st.subheader("âš™ï¸ ä¸Šä¼ é…ç½®")
    
    # çŸ¥è¯†åº“é€‰æ‹©
    if 'knowledge_bases' not in st.session_state:
        st.session_state.knowledge_bases = []
    
    if st.session_state.knowledge_bases:
        # æ„å»ºçŸ¥è¯†åº“é€‰é¡¹
        kb_options = [{"name": "é»˜è®¤çŸ¥è¯†åº“", "id": ""}]  # é»˜è®¤é€‰é¡¹
        kb_options.extend([
            {"name": f"{kb['name']} ({kb['id'][:8]}...)", "id": kb['id']} 
            for kb in st.session_state.knowledge_bases
        ])
        
        selected_kb_index = st.selectbox(
            "é€‰æ‹©ç›®æ ‡çŸ¥è¯†åº“",
            range(len(kb_options)),
            format_func=lambda x: kb_options[x]["name"],
            help="é€‰æ‹©è¦ä¸Šä¼ æ–‡ä»¶çš„ç›®æ ‡çŸ¥è¯†åº“",
            key="kb_selection"
        )
        knowledge_base_id = kb_options[selected_kb_index]["id"]
    else:
        st.info("ğŸ’¡ è¯·å…ˆç‚¹å‡»ä¸Šæ–¹çš„'åˆ·æ–°çŸ¥è¯†åº“åˆ—è¡¨'æŒ‰é’®è·å–å¯ç”¨çš„çŸ¥è¯†åº“")
        knowledge_base_id = ""
    
    col_config1, col_config2 = st.columns(2)
    
    with col_config1:
        # åˆ†å—æ–¹å¼é€‰æ‹©
        chunk_method = st.radio(
            "åˆ†å—æ–¹å¼",
            ["æŒ‰Tokenæ•°åˆ†å—", "æŒ‰åˆ†éš”ç¬¦åˆ†å—"],
            help="é€‰æ‹©æ–‡æ¡£åˆ†å—æ–¹å¼",
            key="chunk_method"
        )
        
        if chunk_method == "æŒ‰Tokenæ•°åˆ†å—":
            chunk_token = st.number_input(
                "åˆ†å—Tokenæ•°",
                min_value=1,
                max_value=1000,
                value=600,
                help="å•ä¸ªçŸ¥è¯†å—çš„æœ€å¤§Tokenæ•°",
                key="chunk_token"
            )
            splitter = None
        else:
            splitter = st.text_input(
                "åˆ†éš”ç¬¦",
                value="\\n",
                help="ä½¿ç”¨è‡ªå®šä¹‰åˆ†éš”ç¬¦è¿›è¡Œåˆ†å—",
                key="splitter"
            )
            # å¤„ç†è½¬ä¹‰å­—ç¬¦
            if splitter == "\\n":
                splitter = "\n"
            elif splitter == "\\t":
                splitter = "\t"
            chunk_token = None
    
    with col_config2:
        # æ–‡ä»¶é€‰æ‹©é€‰é¡¹
        st.write("**æ–‡ä»¶é€‰æ‹©**")
        
        upload_all_files = st.checkbox(
            "ä¸Šä¼ æ‰€æœ‰æ–‡ä»¶",
            value=True,
            help="ä¸Šä¼ final_outputç›®å½•ä¸­çš„æ‰€æœ‰Markdownæ–‡ä»¶",
            key="upload_all"
        )
        
        if not upload_all_files:
            # æ–‡ä»¶é€‰æ‹©å™¨
            final_dir = Path(CONFIG["final_dir"])
            if final_dir.exists():
                md_files = [f.name for f in final_dir.glob("*.md")]
                selected_files = st.multiselect(
                    "é€‰æ‹©è¦ä¸Šä¼ çš„æ–‡ä»¶",
                    options=md_files,
                    default=md_files[:5] if len(md_files) > 5 else md_files,
                    help="é€‰æ‹©ç‰¹å®šæ–‡ä»¶è¿›è¡Œä¸Šä¼ ",
                    key="selected_files"
                )
            else:
                selected_files = []
                st.error("final_outputç›®å½•ä¸å­˜åœ¨")
    
    # é«˜çº§é€‰é¡¹
    with st.expander("ğŸ”§ é«˜çº§é€‰é¡¹", expanded=False):
        col_adv1, col_adv2 = st.columns(2)
        
        with col_adv1:
            # é”™è¯¯å¤„ç†é€‰é¡¹
            continue_on_error = st.checkbox(
                "é‡åˆ°é”™è¯¯æ—¶ç»§ç»­",
                value=True,
                help="å•ä¸ªæ–‡ä»¶å¤±è´¥æ—¶ç»§ç»­å¤„ç†å…¶ä»–æ–‡ä»¶",
                key="continue_on_error"
            )
            
            # å¤‡ä»½é€‰é¡¹
            create_backup = st.checkbox(
                "åˆ›å»ºä¸Šä¼ è®°å½•",
                value=True,
                help="ä¿å­˜ä¸Šä¼ ç»“æœè®°å½•åˆ°æ–‡ä»¶",
                key="create_backup"
            )
        
        with col_adv2:
            # é‡è¯•é€‰é¡¹
            max_retries = st.number_input(
                "æœ€å¤§é‡è¯•æ¬¡æ•°",
                min_value=0,
                max_value=5,
                value=3,
                help="APIè°ƒç”¨å¤±è´¥æ—¶çš„é‡è¯•æ¬¡æ•°",
                key="max_retries"
            )
    
    # å¼€å§‹ä¸Šä¼ æŒ‰é’®
    st.markdown("---")
    st.subheader("ğŸš€ å¼€å§‹ä¸Šä¼ ")
    
    # æ˜¾ç¤ºä¸Šä¼ é¢„è§ˆ
    if upload_all_files:
        st.info(f"ğŸ“Š å°†ä¸Šä¼  {final_files} ä¸ªæ–‡ä»¶åˆ°çŸ¥è¯†åº“")
    else:
        selected_count = len(selected_files) if 'selected_files' in locals() else 0
        st.info(f"ğŸ“Š å°†ä¸Šä¼  {selected_count} ä¸ªé€‰ä¸­çš„æ–‡ä»¶åˆ°çŸ¥è¯†åº“")
    
    # ä¸Šä¼ æŒ‰é’®
    if st.button("ğŸš€ å¼€å§‹ä¸Šä¼ åˆ°çŸ¥è¯†åº“", type="primary", key="start_kb_upload"):
        # å‡†å¤‡ä¸Šä¼ å‚æ•°
        upload_params = {
            "api_key": api_key,
            "endpoint": endpoint,
            "knowledge_base_id": knowledge_base_id if knowledge_base_id else None,
            "chunk_token": chunk_token,
            "splitter": splitter,
            "continue_on_error": continue_on_error,
            "max_retries": max_retries,
            "create_backup": create_backup,
            "selected_files": selected_files if not upload_all_files and 'selected_files' in locals() else None
        }
        
        # å¼€å§‹ä¸Šä¼ 
        start_knowledge_base_upload(CONFIG, **upload_params)
    
    # å¯¼èˆªæŒ‰é’®
    st.markdown("---")
    col1, col2, col3 = st.columns([1, 2, 1])
    with col1:
        if st.button("â¬…ï¸ ä¸Šä¸€æ­¥", help="è¿”å›ç»“æœæŸ¥çœ‹é¡µé¢", key="kb_prev_btn"):
            st.session_state.current_step = "ç»“æœæŸ¥çœ‹"
            st.rerun()
    with col3:
        if st.button("â¡ï¸ ä¸‹ä¸€æ­¥", help="å‰å¾€é—®ç­”ç³»ç»Ÿ", key="kb_next_btn"):
            st.session_state.current_step = "é—®ç­”ç³»ç»Ÿ"
            st.rerun()


def get_knowledge_base_list(api_key):
    """è·å–å¹¶æ˜¾ç¤ºçŸ¥è¯†åº“åˆ—è¡¨"""
    st.info("ğŸ”„ æ­£åœ¨è·å–çŸ¥è¯†åº“åˆ—è¡¨...")
    
    try:
        from .api_clients import KnowledgeBaseAPI
        
        client = KnowledgeBaseAPI(api_key)
        result = client.get_knowledge_bases()
        
        if result and "knowledge_base" in result:
            knowledge_bases = result["knowledge_base"]
            
            if knowledge_bases:
                st.success(f"âœ… æˆåŠŸè·å– {len(knowledge_bases)} ä¸ªçŸ¥è¯†åº“")
                
                # æ˜¾ç¤ºçŸ¥è¯†åº“åˆ—è¡¨
                kb_data = []
                for kb in knowledge_bases:
                    kb_data.append({
                        "çŸ¥è¯†åº“ID": kb.get("id", "")[:12] + "..." if len(kb.get("id", "")) > 12 else kb.get("id", ""),
                        "åç§°": kb.get("name", ""),
                        "æè¿°": kb.get("desc", "")[:50] + "..." if len(kb.get("desc", "")) > 50 else kb.get("desc", ""),
                        "æ–‡æ¡£æ•°": kb.get("doc", 0),
                        "çŸ¥è¯†å—æ•°": kb.get("chunk", 0),
                        "Tokenæ•°": kb.get("token", 0)
                    })
                
                st.dataframe(pd.DataFrame(kb_data), width='stretch')
                return knowledge_bases
            else:
                st.warning("âš ï¸ æœªå‘ç°ä»»ä½•çŸ¥è¯†åº“")
                return []
                
        elif result and "error" in result:
            st.error(f"âŒ è·å–çŸ¥è¯†åº“åˆ—è¡¨å¤±è´¥: {result['message']}")
            return []
        else:
            st.error("âŒ è·å–çŸ¥è¯†åº“åˆ—è¡¨å¤±è´¥")
            return []
            
    except Exception as e:
        st.error(f"âŒ è·å–çŸ¥è¯†åº“åˆ—è¡¨å‡ºé”™: {str(e)}")
        return []


def start_knowledge_base_upload(config, **params):
    """å¼€å§‹çŸ¥è¯†åº“ä¸Šä¼ """
    st.info("ğŸš€ å¼€å§‹ä¸Šä¼ æ–‡ä»¶åˆ°çŸ¥è¯†åº“...")
    log_activity("å¼€å§‹çŸ¥è¯†åº“ä¸Šä¼ ")
    
    # åˆ›å»ºè¿›åº¦æ¡å’ŒçŠ¶æ€æ˜¾ç¤º
    progress_bar = st.progress(0)
    status_text = st.empty()
    result_container = st.empty()
    
    try:
        from .api_clients import KnowledgeBaseAPI
        
        # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
        status_text.text("ğŸ” åˆå§‹åŒ–çŸ¥è¯†åº“APIå®¢æˆ·ç«¯...")
        client = KnowledgeBaseAPI(params["api_key"])
        
        # ç¡®å®šè¦ä¸Šä¼ çš„æ–‡ä»¶
        final_dir = Path(config["final_dir"])
        if params["selected_files"]:
            # ä¸Šä¼ é€‰ä¸­çš„æ–‡ä»¶
            files_to_upload = [final_dir / filename for filename in params["selected_files"]]
            upload_mode = "selected"
        else:
            # ä¸Šä¼ æ‰€æœ‰æ–‡ä»¶
            files_to_upload = list(final_dir.glob("*.md"))
            upload_mode = "all"
        
        if not files_to_upload:
            st.error("âŒ æ²¡æœ‰æ‰¾åˆ°è¦ä¸Šä¼ çš„æ–‡ä»¶")
            return
        
        progress_bar.progress(10)
        status_text.text(f"ğŸ“§ å‡†å¤‡ä¸Šä¼  {len(files_to_upload)} ä¸ªæ–‡ä»¶...")
        
        # æ ¹æ®ä¸Šä¼ æ¨¡å¼é€‰æ‹©ä¸åŒçš„ä¸Šä¼ æ–¹æ³•
        if upload_mode == "all":
            # ä½¿ç”¨æ‰¹é‡ä¸Šä¼ åŠŸèƒ½ï¼ˆä¸Šä¼ æ•´ä¸ªç›®å½•ï¼‰
            upload_result = client.upload_markdown_files_from_directory(
                directory_path=str(final_dir),
                knowledge_base_id=params["knowledge_base_id"],
                chunk_token=params["chunk_token"] or 600,
                splitter=params["splitter"],
                batch_size=10  # ä½¿ç”¨å›ºå®šçš„æ‰¹æ¬¡å¤§å°
            )
        else:
            # é€ä¸ªä¸Šä¼ é€‰ä¸­çš„æ–‡ä»¶
            upload_result = upload_selected_files(
                client, files_to_upload, params, progress_bar, status_text
            )
        
        progress_bar.progress(90)
        status_text.text("ğŸ“ å¤„ç†ä¸Šä¼ ç»“æœ...")
        
        if "error" not in upload_result:
            progress_bar.progress(100)
            status_text.empty()
            
            # æ˜¾ç¤ºä¸Šä¼ ç»“æœ
            with result_container.container():
                st.success("ğŸ‰ çŸ¥è¯†åº“ä¸Šä¼ å®Œæˆï¼")
                
                # ç»Ÿè®¡ä¿¡æ¯ - å…¼å®¹ä¸¤ç§ä¸Šä¼ æ–¹å¼çš„ç»“æœæ ¼å¼
                col1, col2, col3, col4 = st.columns(4)
                
                # ç»Ÿä¸€å¤„ç†ä¸åŒä¸Šä¼ æ–¹å¼çš„ç»“æœæ ¼å¼
                total_files = upload_result.get("total_count", upload_result.get("total_files", 0))
                successful_uploads = upload_result.get("success_count", upload_result.get("successful_uploads", 0))
                failed_uploads = upload_result.get("failed_count", upload_result.get("failed_uploads", 0))
                batches_processed = upload_result.get("batches_processed", 1)
                
                with col1:
                    st.metric("æ€»æ–‡ä»¶æ•°", total_files)
                
                with col2:
                    st.metric("ä¸Šä¼ æˆåŠŸ", successful_uploads)
                
                with col3:
                    st.metric("ä¸Šä¼ å¤±è´¥", failed_uploads)
                
                with col4:
                    st.metric("å¤„ç†æ‰¹æ¬¡", batches_processed)
                
                # æˆåŠŸä¸Šä¼ çš„æ–‡ä»¶ - å…¼å®¹ä¸¤ç§æ ¼å¼
                uploaded_files = upload_result.get("uploaded_files", [])
                success_files = upload_result.get("success_files", [])
                
                if uploaded_files or success_files:
                    st.subheader("âœ… æˆåŠŸä¸Šä¼ çš„æ–‡ä»¶")
                    
                    # å¤„ç†æ‰¹é‡ä¸Šä¼ çš„ç»“æœæ ¼å¼
                    if uploaded_files:
                        success_data = []
                        for doc in uploaded_files:
                            success_data.append({
                                "æ–‡æ¡£ID": doc.get("doc_id", ""),
                                "æ–‡æ¡£åç§°": doc.get("doc_name", "")
                            })
                        
                        if success_data:
                            st.dataframe(pd.DataFrame(success_data))
                    
                    # å¤„ç†é€‰æ‹©æ–‡ä»¶ä¸Šä¼ çš„ç»“æœæ ¼å¼
                    elif success_files:
                        for file_info in success_files:
                            if isinstance(file_info, dict):
                                file_name = file_info.get('file', file_info.get('filename', 'æœªçŸ¥æ–‡ä»¶'))
                                chunks = file_info.get('chunks', file_info.get('chunks_count', 0))
                                size = file_info.get('size', 0)
                                st.write(f"ğŸ“„ {file_name} - {chunks} ä¸ªåˆ†ç‰‡ ({size} å­—ç¬¦)")
                            else:
                                st.write(f"ğŸ“„ {file_info}")
                
                # å¤±è´¥çš„æ–‡ä»¶ - å…¼å®¹ä¸¤ç§æ ¼å¼
                failed_files = upload_result.get("failed_files", [])
                if failed_files:
                    st.subheader("âŒ ä¸Šä¼ å¤±è´¥çš„æ–‡ä»¶")
                    for failed in failed_files:
                        if isinstance(failed, dict):
                            # æ‰¹é‡ä¸Šä¼ æ ¼å¼
                            if 'file_name' in failed:
                                st.error(f"{failed['file_name']}: {failed['error']}")
                            # é€‰æ‹©æ–‡ä»¶ä¸Šä¼ æ ¼å¼
                            elif 'file' in failed:
                                st.error(f"{failed['file']}: {failed['error']}")
                            else:
                                st.error(f"æœªçŸ¥æ–‡ä»¶: {failed.get('error', 'æœªçŸ¥é”™è¯¯')}")
                        else:
                            st.error(str(failed))
                
                # ä¿å­˜ä¸Šä¼ è®°å½•
                if params["create_backup"]:
                    backup_filename = f"kb_upload_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                    backup_path = Path(config["final_dir"]) / backup_filename
                    
                    with open(backup_path, 'w', encoding='utf-8') as f:
                        json.dump(upload_result, f, indent=2, ensure_ascii=False)
                    
                    st.info(f"ğŸ“„ ä¸Šä¼ è®°å½•å·²ä¿å­˜åˆ°: {backup_filename}")
                
                log_activity(f"çŸ¥è¯†åº“ä¸Šä¼ å®Œæˆ: {successful_uploads}/{total_files} æˆåŠŸ")
        
        else:
            progress_bar.progress(0)
            status_text.empty()
            result_container.error(f"âŒ ä¸Šä¼ å¤±è´¥: {upload_result['error']}")
            log_activity(f"çŸ¥è¯†åº“ä¸Šä¼ å¤±è´¥: {upload_result['error']}")
    
    except Exception as e:
        progress_bar.progress(0)
        status_text.empty()
        result_container.error(f"âŒ ä¸Šä¼ è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        log_activity(f"çŸ¥è¯†åº“ä¸Šä¼ é”™è¯¯: {str(e)}")
        st.exception(e)


def upload_selected_files(client, files_to_upload, params, progress_bar, status_text):
    """
    ä¸Šä¼ é€‰ä¸­çš„æ–‡ä»¶åˆ°çŸ¥è¯†åº“
    
    Args:
        client: KnowledgeBaseAPIå®¢æˆ·ç«¯
        files_to_upload: è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        params: ä¸Šä¼ å‚æ•°
        progress_bar: è¿›åº¦æ¡
        status_text: çŠ¶æ€æ–‡æœ¬
    
    Returns:
        dict: ä¸Šä¼ ç»“æœ
    """
    import time
    from datetime import datetime
    
    upload_results = {
        "success_count": 0,
        "failed_count": 0,
        "total_count": len(files_to_upload),
        "failed_files": [],
        "success_files": [],
        "upload_time": datetime.now().strftime('%Y%m%d_%H%M%S')
    }
    
    try:
        # é€ä¸ªä¸Šä¼ æ–‡ä»¶
        for i, file_path in enumerate(files_to_upload):
            try:
                # æ›´æ–°è¿›åº¦
                progress = 20 + (i / len(files_to_upload)) * 60  # 20-80%çš„è¿›åº¦ç”¨äºæ–‡ä»¶ä¸Šä¼ 
                progress_bar.progress(int(progress))
                status_text.text(f"ğŸ“¤ æ­£åœ¨ä¸Šä¼ æ–‡ä»¶ {i+1}/{len(files_to_upload)}: {file_path.name}")
                
                # è¯»å–æ–‡ä»¶å†…å®¹
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                if not content.strip():
                    upload_results["failed_files"].append({
                        "file": file_path.name,
                        "error": "æ–‡ä»¶å†…å®¹ä¸ºç©º"
                    })
                    upload_results["failed_count"] += 1
                    continue
                
                # è°ƒç”¨å•æ–‡ä»¶ä¸Šä¼ API
                result = client.upload_markdown_content(
                    content=content,
                    filename=file_path.name,
                    knowledge_base_id=params["knowledge_base_id"],
                    chunk_token=params["chunk_token"] or 600,
                    splitter=params["splitter"]
                )
                
                if result and "error" not in result:
                    upload_results["success_files"].append({
                        "file": file_path.name,
                        "chunks": result.get("chunks_count", 0),
                        "size": len(content)
                    })
                    upload_results["success_count"] += 1
                else:
                    error_msg = result.get("error", "æœªçŸ¥é”™è¯¯") if result else "APIè°ƒç”¨å¤±è´¥"
                    upload_results["failed_files"].append({
                        "file": file_path.name,
                        "error": error_msg
                    })
                    upload_results["failed_count"] += 1
                
                # æ·»åŠ å»¶è¿Ÿé¿å…APIé™æµ
                if i < len(files_to_upload) - 1:
                    time.sleep(1)
                    
            except Exception as e:
                upload_results["failed_files"].append({
                    "file": file_path.name,
                    "error": f"å¤„ç†é”™è¯¯: {str(e)}"
                })
                upload_results["failed_count"] += 1
                
                # å¦‚æœè®¾ç½®äº†é‡åˆ°é”™è¯¯æ—¶ç»§ç»­ï¼Œåˆ™ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶
                if not params.get("continue_on_error", True):
                    break
        
        return upload_results
        
    except Exception as e:
        return {
            "error": f"æ‰¹é‡ä¸Šä¼ è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
            "success_count": upload_results["success_count"],
            "failed_count": upload_results["failed_count"],
            "total_count": upload_results["total_count"]
        }
